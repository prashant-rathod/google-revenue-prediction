{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "from sklearn import preprocessing\n",
    "import datetime\n",
    "\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's read the data from our clean CSVs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channelGrouping</th>\n",
       "      <th>date</th>\n",
       "      <th>fullVisitorId</th>\n",
       "      <th>visitId</th>\n",
       "      <th>visitNumber</th>\n",
       "      <th>visitStartTime</th>\n",
       "      <th>device.browser</th>\n",
       "      <th>device.deviceCategory</th>\n",
       "      <th>device.isMobile</th>\n",
       "      <th>device.operatingSystem</th>\n",
       "      <th>...</th>\n",
       "      <th>trafficSource.campaign</th>\n",
       "      <th>trafficSource.isTrueDirect</th>\n",
       "      <th>trafficSource.keyword</th>\n",
       "      <th>trafficSource.medium</th>\n",
       "      <th>trafficSource.referralPath</th>\n",
       "      <th>trafficSource.source</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>2018-05-11</td>\n",
       "      <td>7.460955e+18</td>\n",
       "      <td>1526099341</td>\n",
       "      <td>2</td>\n",
       "      <td>1.526099e+09</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>516</td>\n",
       "      <td>4</td>\n",
       "      <td>1754</td>\n",
       "      <td>62</td>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-05-11</td>\n",
       "      <td>4.602525e+17</td>\n",
       "      <td>1526064483</td>\n",
       "      <td>166</td>\n",
       "      <td>1.526064e+09</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>516</td>\n",
       "      <td>3</td>\n",
       "      <td>1754</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2018-05-11</td>\n",
       "      <td>3.461809e+18</td>\n",
       "      <td>1526067157</td>\n",
       "      <td>2</td>\n",
       "      <td>1.526067e+09</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>516</td>\n",
       "      <td>4</td>\n",
       "      <td>1754</td>\n",
       "      <td>62</td>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-05-11</td>\n",
       "      <td>9.751295e+17</td>\n",
       "      <td>1526107551</td>\n",
       "      <td>4</td>\n",
       "      <td>1.526108e+09</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>516</td>\n",
       "      <td>3</td>\n",
       "      <td>1754</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2018-05-11</td>\n",
       "      <td>8.381673e+18</td>\n",
       "      <td>1526060254</td>\n",
       "      <td>1</td>\n",
       "      <td>1.526060e+09</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>516</td>\n",
       "      <td>4</td>\n",
       "      <td>1754</td>\n",
       "      <td>62</td>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   channelGrouping        date  fullVisitorId     visitId  visitNumber  \\\n",
       "0                4  2018-05-11   7.460955e+18  1526099341            2   \n",
       "1                2  2018-05-11   4.602525e+17  1526064483          166   \n",
       "2                4  2018-05-11   3.461809e+18  1526067157            2   \n",
       "3                2  2018-05-11   9.751295e+17  1526107551            4   \n",
       "4                4  2018-05-11   8.381673e+18  1526060254            1   \n",
       "\n",
       "   visitStartTime  device.browser  device.deviceCategory  device.isMobile  \\\n",
       "0    1.526099e+09              25                      1             True   \n",
       "1    1.526064e+09              25                      0            False   \n",
       "2    1.526067e+09              25                      0            False   \n",
       "3    1.526108e+09              25                      1             True   \n",
       "4    1.526060e+09              33                      2             True   \n",
       "\n",
       "   device.operatingSystem   ...     trafficSource.campaign  \\\n",
       "0                       0   ...                         25   \n",
       "1                       6   ...                         25   \n",
       "2                       2   ...                         25   \n",
       "3                      20   ...                         25   \n",
       "4                      17   ...                         25   \n",
       "\n",
       "   trafficSource.isTrueDirect  trafficSource.keyword  trafficSource.medium  \\\n",
       "0                           0                    516                     4   \n",
       "1                           0                    516                     3   \n",
       "2                           0                    516                     4   \n",
       "3                           0                    516                     3   \n",
       "4                           1                    516                     4   \n",
       "\n",
       "   trafficSource.referralPath  trafficSource.source  year  month  day  weekday  \n",
       "0                        1754                    62  2018      5   11        4  \n",
       "1                        1754                     0  2018      5   11        4  \n",
       "2                        1754                    62  2018      5   11        4  \n",
       "3                        1754                     0  2018      5   11        4  \n",
       "4                        1754                    62  2018      5   11        4  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"trainEncoded.csv\")\n",
    "test_df = pd.read_csv(\"testEncoded.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's modify the data a bit. We need to encode the string type columns into numerical type using label encoding. We will also split the train and dev data and remove some columns that seem to be unimportant.\n",
    "\n",
    "Since the target value has such a huge range, lets take the log and predict for the log of transactionRevenue. It will be reversed using exponent function before calculating RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:14: FutureWarning: Comparing Series of datetimes with 'datetime.date'.  Currently, the\n",
      "'datetime.date' is coerced to a datetime. In the future pandas will\n",
      "not coerce, and a TypeError will be raised. To retain the current\n",
      "behavior, convert the 'datetime.date' to a datetime with\n",
      "'pd.Timestamp'.\n",
      "  \n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:15: FutureWarning: Comparing Series of datetimes with 'datetime.date'.  Currently, the\n",
      "'datetime.date' is coerced to a datetime. In the future pandas will\n",
      "not coerce, and a TypeError will be raised. To retain the current\n",
      "behavior, convert the 'datetime.date' to a datetime with\n",
      "'pd.Timestamp'.\n",
      "  from ipykernel import kernelapp as app\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:16: FutureWarning: Comparing Series of datetimes with 'datetime.date'.  Currently, the\n",
      "'datetime.date' is coerced to a datetime. In the future pandas will\n",
      "not coerce, and a TypeError will be raised. To retain the current\n",
      "behavior, convert the 'datetime.date' to a datetime with\n",
      "'pd.Timestamp'.\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "train_df.fillna(train_df.mean(), inplace=True)\n",
    "test_df.fillna(test_df.mean(), inplace=True)\n",
    "\n",
    "train_df['date'] = pd.to_datetime(train_df['date'], format='%Y-%m-%d', errors='ignore')\n",
    "test_df['date'] = pd.to_datetime(test_df['date'], format='%Y-%m-%d', errors='ignore')\n",
    "\n",
    "train_y = train_df[\"totals.transactionRevenue\"].values\n",
    "train_id = train_df[\"fullVisitorId\"].values\n",
    "\n",
    "test_y = test_df[\"totals.transactionRevenue\"].values\n",
    "test_id = test_df[\"fullVisitorId\"].values\n",
    "\n",
    "# Split the train dataset into development and valid based on time \n",
    "dev_df = train_df[train_df['date']<=datetime.date(2018, 1, 1)]\n",
    "dev_df = dev_df[dev_df['date']>=datetime.date(2017, 1, 1)]\n",
    "val_df = train_df[train_df['date']>datetime.date(2018, 1, 1)]\n",
    "dev_y = np.log1p(dev_df[\"totals.transactionRevenue\"].values)\n",
    "val_y = np.log1p(val_df[\"totals.transactionRevenue\"].values)\n",
    "\n",
    "#exclude irrelevant data like ID and also target variables from train data!\n",
    "cols_to_exclude = ['totals.transactionRevenue','totals.totalTransactionRevenue','totals.transactions','date','fullVisitorId', 'visitId']\n",
    "dev_X = dev_df.copy()\n",
    "val_X = val_df.copy()\n",
    "test_X = test_df.copy()\n",
    "dev_X.drop(cols_to_exclude, axis=1, inplace=True)\n",
    "val_X.drop(cols_to_exclude, axis=1, inplace=True)\n",
    "test_X.drop(cols_to_exclude, axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for a baseline!\n",
    "\n",
    "Taking all zero's is not exactly right since although most values are zeroes, we are finally looking at revenue per customer (not per visit). So let's take the mean revenue of all customers.\n",
    "\n",
    "RMSE: 13.85\n",
    "\n",
    "That's pretty bad!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.89539511019656\n",
      "CPU times: user 104 ms, sys: 17.9 ms, total: 122 ms\n",
      "Wall time: 128 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#BASELINE!\n",
    "\n",
    "val_pred_rf1 = pd.DataFrame({\"fullVisitorId\":val_df[\"fullVisitorId\"].values})\n",
    "val_pred_rf1[\"transactionRevenue\"] = val_df[\"totals.transactionRevenue\"].values\n",
    "\n",
    "val_pred_rf1 = val_pred_rf1.groupby(\"fullVisitorId\")[\"transactionRevenue\"].sum().reset_index()\n",
    "pred_val_group_mean = val_pred_rf1[\"transactionRevenue\"].mean()\n",
    "val_pred_rf1[\"PredictedRevenue\"] = pred_val_group_mean\n",
    "print(np.sqrt(metrics.mean_squared_error(np.log1p(val_pred_rf1[\"transactionRevenue\"].values), np.log1p(val_pred_rf1[\"PredictedRevenue\"].values))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try a random forest to see if it helps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              importance\n",
      "totals.pageviews                                0.219785\n",
      "totals.timeOnSite                               0.118630\n",
      "visitStartTime                                  0.112234\n",
      "day                                             0.065504\n",
      "totals.hits                                     0.065438\n",
      "geoNetwork.country                              0.063040\n",
      "totals.sessionQualityDim                        0.052284\n",
      "visitNumber                                     0.043714\n",
      "geoNetwork.networkDomain                        0.038508\n",
      "weekday                                         0.036407\n",
      "geoNetwork.city                                 0.027396\n",
      "trafficSource.referralPath                      0.024322\n",
      "device.operatingSystem                          0.021062\n",
      "geoNetwork.metro                                0.017790\n",
      "geoNetwork.region                               0.017645\n",
      "month                                           0.013310\n",
      "trafficSource.isTrueDirect                      0.011156\n",
      "device.browser                                  0.008867\n",
      "channelGrouping                                 0.008394\n",
      "trafficSource.source                            0.006495\n",
      "trafficSource.medium                            0.005515\n",
      "device.deviceCategory                           0.005042\n",
      "device.isMobile                                 0.004913\n",
      "trafficSource.adwordsClickInfo.gclId            0.004082\n",
      "trafficSource.keyword                           0.002524\n",
      "geoNetwork.subContinent                         0.001558\n",
      "trafficSource.adContent                         0.001233\n",
      "geoNetwork.continent                            0.000871\n",
      "trafficSource.campaign                          0.000827\n",
      "trafficSource.adwordsClickInfo.adNetworkType    0.000377\n",
      "trafficSource.adwordsClickInfo.slot             0.000358\n",
      "trafficSource.adwordsClickInfo.isVideoAd        0.000355\n",
      "trafficSource.adwordsClickInfo.page             0.000348\n",
      "year                                            0.000019\n",
      "totals.newVisits                                0.000000\n",
      "totals.bounces                                  0.000000\n"
     ]
    }
   ],
   "source": [
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Instantiate model with 100 decision trees\n",
    "\n",
    "def run_rf(train_X, train_y, val_X, val_y, test_X):\n",
    "    rf = RandomForestRegressor(n_estimators = 100, random_state = 42)\n",
    "    rf.fit(train_X, train_y);\n",
    "    feature_importances = pd.DataFrame(rf.feature_importances_,\n",
    "                                   index = train_X.columns,\n",
    "                                    columns=['importance']).sort_values('importance', ascending=False)\n",
    "    print (feature_importances)\n",
    "    pred_val_y = rf.predict(val_X)\n",
    "    pred_test_y = rf.predict(test_X)\n",
    "    return rf, pred_val_y, pred_test_y\n",
    "# Train the model on training data\n",
    "rf, pred_val_rf, pred_test_rf = run_rf(dev_X, dev_y, val_X, val_y, test_X);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5089051375290736\n"
     ]
    }
   ],
   "source": [
    "#validation\n",
    "\n",
    "pred_val_rf[pred_val_rf<0] = 0\n",
    "val_pred_rf = pd.DataFrame({\"fullVisitorId\":val_df[\"fullVisitorId\"].values})\n",
    "val_pred_rf[\"transactionRevenue\"] = val_df[\"totals.transactionRevenue\"].values\n",
    "val_pred_rf[\"PredictedRevenue\"] = np.expm1(pred_val_rf)\n",
    "val_pred_rf = val_pred_rf.groupby(\"fullVisitorId\")[\"transactionRevenue\", \"PredictedRevenue\"].sum().reset_index()\n",
    "print(np.sqrt(metrics.mean_squared_error(np.log1p(val_pred_rf[\"transactionRevenue\"].values), np.log1p(val_pred_rf[\"PredictedRevenue\"].values))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2573563949499444\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "pred_test_rf[pred_test_rf<0] = 0\n",
    "test_pred_rf = pd.DataFrame({\"fullVisitorId\":test_df[\"fullVisitorId\"].values})\n",
    "test_pred_rf[\"transactionRevenue\"] = test_df[\"totals.transactionRevenue\"].values\n",
    "test_pred_rf[\"PredictedRevenue\"] = np.expm1(pred_test_rf)\n",
    "test_pred_rf = test_pred_rf.groupby(\"fullVisitorId\")[\"transactionRevenue\", \"PredictedRevenue\"].sum().reset_index()\n",
    "print(np.sqrt(metrics.mean_squared_error(np.log1p(test_pred_rf[\"transactionRevenue\"].values), np.log1p(test_pred_rf[\"PredictedRevenue\"].values))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's pretty impressive! A really nominally tuned random forest did loads better than baseline!\n",
    "\n",
    "Since this is promising, let's try to tune those hyper parameters some more. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [20, 51, 82, 113, 144, 175, 206, 237, 268, 300], 'max_features': ['auto', 'sqrt'], 'max_depth': [6, 10, 15, 20, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 20, stop = 300, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(6, 20, num = 4)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "print(random_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed: 68.2min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 284.6min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 607.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "          estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
       "          fit_params=None, iid='warn', n_iter=100, n_jobs=-1,\n",
       "          param_distributions={'n_estimators': [20, 51, 82, 113, 144, 175, 206, 237, 268, 300], 'max_features': ['auto', 'sqrt'], 'max_depth': [6, 10, 15, 20, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]},\n",
       "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=2)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor()\n",
    "# Random search of parameters, using 3 fold cross validation\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(dev_X, dev_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 300,\n",
       " 'min_samples_split': 5,\n",
       " 'min_samples_leaf': 4,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': None,\n",
       " 'bootstrap': False}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That took 12 hours! And we've got ourselves a new set of hyperparameter values.\n",
    "\n",
    "Phew! Now let's see how much of a difference all that computing made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                importance\n",
      "totals.pageviews                              1.892682e-01\n",
      "totals.hits                                   1.628767e-01\n",
      "totals.timeOnSite                             1.073618e-01\n",
      "totals.sessionQualityDim                      9.738054e-02\n",
      "visitStartTime                                6.867285e-02\n",
      "day                                           4.158431e-02\n",
      "visitNumber                                   3.140015e-02\n",
      "geoNetwork.country                            3.008232e-02\n",
      "month                                         2.741987e-02\n",
      "geoNetwork.networkDomain                      2.470687e-02\n",
      "weekday                                       2.427301e-02\n",
      "trafficSource.referralPath                    2.285246e-02\n",
      "geoNetwork.city                               2.257888e-02\n",
      "geoNetwork.metro                              1.738148e-02\n",
      "geoNetwork.continent                          1.653013e-02\n",
      "geoNetwork.region                             1.585994e-02\n",
      "device.operatingSystem                        1.517795e-02\n",
      "totals.newVisits                              1.159870e-02\n",
      "channelGrouping                               1.153176e-02\n",
      "geoNetwork.subContinent                       9.734556e-03\n",
      "trafficSource.medium                          8.103232e-03\n",
      "trafficSource.isTrueDirect                    7.424426e-03\n",
      "trafficSource.source                          6.975799e-03\n",
      "device.browser                                5.908901e-03\n",
      "device.isMobile                               5.849205e-03\n",
      "device.deviceCategory                         5.645453e-03\n",
      "trafficSource.keyword                         3.735635e-03\n",
      "totals.bounces                                3.207433e-03\n",
      "trafficSource.adwordsClickInfo.gclId          2.094256e-03\n",
      "trafficSource.campaign                        6.621784e-04\n",
      "trafficSource.adContent                       4.820434e-04\n",
      "trafficSource.adwordsClickInfo.adNetworkType  4.167118e-04\n",
      "trafficSource.adwordsClickInfo.slot           4.131053e-04\n",
      "trafficSource.adwordsClickInfo.isVideoAd      4.085707e-04\n",
      "trafficSource.adwordsClickInfo.page           3.997442e-04\n",
      "year                                          8.901254e-07\n",
      "CPU times: user 5min 15s, sys: 3.9 s, total: 5min 19s\n",
      "Wall time: 5min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "best_random = rf_random.best_estimator_\n",
    "\n",
    "def run_rf_model(model, train_X, train_y, val_X, val_y, test_X):\n",
    "    #rf = RandomForestRegressor(n_estimators = 100, max_depth = 6, min_samples_split = , max_features = \"sqrt\", random_state = 42)\n",
    "    model.fit(train_X, train_y);\n",
    "    \n",
    "    pred_val_y = model.predict(val_X)\n",
    "    pred_test_y = model.predict(test_X)\n",
    "    feature_importances = pd.DataFrame(model.feature_importances_,\n",
    "                                   index = train_X.columns,\n",
    "                                    columns=['importance']).sort_values('importance', ascending=False)\n",
    "    print (feature_importances)\n",
    "    return rf, pred_val_y, pred_test_y\n",
    "# Train the model on training data\n",
    "rf, pred_val_rf, pred_test_rf = run_rf_model(best_random, dev_X, dev_y, val_X, val_y, test_X);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4320818834553026\n",
      "CPU times: user 546 ms, sys: 133 ms, total: 679 ms\n",
      "Wall time: 912 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#validation\n",
    "\n",
    "pred_val_rf[pred_val_rf<0] = 0\n",
    "val_pred_rf = pd.DataFrame({\"fullVisitorId\":val_df[\"fullVisitorId\"].values})\n",
    "val_pred_rf[\"transactionRevenue\"] = val_df[\"totals.transactionRevenue\"].values\n",
    "val_pred_rf[\"PredictedRevenue\"] = np.expm1(pred_val_rf)\n",
    "val_pred_rf = val_pred_rf.groupby(\"fullVisitorId\")[\"transactionRevenue\", \"PredictedRevenue\"].sum().reset_index()\n",
    "print(np.sqrt(metrics.mean_squared_error(np.log1p(val_pred_rf[\"transactionRevenue\"].values), np.log1p(val_pred_rf[\"PredictedRevenue\"].values))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.017829627946382\n",
      "CPU times: user 655 ms, sys: 87.1 ms, total: 742 ms\n",
      "Wall time: 776 ms\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "pred_test_rf[pred_test_rf<0] = 0\n",
    "test_pred_rf = pd.DataFrame({\"fullVisitorId\":test_df[\"fullVisitorId\"].values})\n",
    "test_pred_rf[\"transactionRevenue\"] = test_df[\"totals.transactionRevenue\"].values\n",
    "test_pred_rf[\"PredictedRevenue\"] = np.expm1(pred_test_rf)\n",
    "test_pred_rf = test_pred_rf.groupby(\"fullVisitorId\")[\"transactionRevenue\", \"PredictedRevenue\"].sum().reset_index()\n",
    "print(np.sqrt(metrics.mean_squared_error(np.log1p(test_pred_rf[\"transactionRevenue\"].values), np.log1p(test_pred_rf[\"PredictedRevenue\"].values))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's the best so far! And since we're working in the log space, I would say that's pretty impressive.\n",
    "\n",
    "Training time of 6 minutes isn't that terrible either!\n",
    "\n",
    "Let's see if there are any other models that do as well and then decide if this is worth exploring further. I don't want to tune my hyperparameters for another 12 hours if there is a better model out there!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
